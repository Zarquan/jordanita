#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2025, Manchester (http://www.manchester.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-indent
#
# AIMetrics: []
#

    Target:

        Ideas for Coral backlog ..
        https://confluence.skatelescope.org/pages/viewpage.action?pageId=335226135

    Resources:

        SRCNet Technical Coordination Group (TCG)
        https://confluence.skatelescope.org/pages/viewpage.action?pageId=330635919

        Follow-up from mini-ATAM meeting - SKA Regional Centre Network project - SKAO Community Confluence
        https://confluence.skatelescope.org/display/SRCSC/Follow-up+from+mini-ATAM+meeting

        SRC-DM (Data Management) Â· GitLab
        https://gitlab.com/ska-telescope/src/src-dm

        SP-4516 Software priority list - SKA Regional Centre Network project - SKAO Community Confluence
        https://confluence.skatelescope.org/display/SRCSC/SP-4516+Software+priority+list
        https://confluence.skatelescope.org/pages/editpage.action?pageId=300789389



        SRCNet v0.2 Components and Connectors Architectural View - SKA Regional Centre Network project - SKAO Community Confluence
        https://confluence.skatelescope.org/display/SRCSC/SRCNet+v0.2+Components+and+Connectors+Architectural+View

        SRCNet v0.2 Modules View - SKA Regional Centre Network project - SKAO Community Confluence
        https://confluence.skatelescope.org/display/SRCSC/SRCNet+v0.2+Modules+View

        Execution Broker Sequence Diagram - SKA Regional Centre Network project - SKAO Community Confluence
        https://confluence.skatelescope.org/display/SRCSC/Execution+Broker+Sequence+Diagram



    Result:

        Work in progress ...

# -----------------------------------------------------

    Learn how to use the template API with OpenAPI.

        https://gitlab.com/ska-telescope/src/src-api/ska-src-api-template

        Figure out how to combine the api-template with a service API generated by OpenAPI.
        Enables us to develop service APIs schema first.


# -----------------------------------------------------

[SP-5237] Implement a workflow execution service (Global Service)
https://jira.skatelescope.org/browse/SP-5237

Currently already in the backlog

Specifically requires the SRCNet Python framework, which will make it harder to develop.
We can work on the Java implementation in our unmanaged 50% and then port the changes across.

AC1: A REST service implementing the services
AC2: Connection to at least 1, ideally 2, real (or mockup) Execution Broker services
AC3: A Demo to the ART

Coral probably won't be allowed to work on this as it is.
However, there may be a case for developing a similar service for interactice tasks only.

# -----------------------------------------------------

Implement WorkflowExecution for interactive tasks (notebook, desktop, etc.).

Assuming we will be using compute-api and Panda for batch mode tasks,
we still need something to edit and launch interactive tasks.

At the moment we are embedding things directly into the ScienceGatweay UI,
but Jesus has stated that he wants to have a REST API that can also be called
from a command line client.

The WorkflowExecution service moves the business logic for editing and submitting the workflow step from the UI client to the service API.

This builds on the work we have done for SoftwareDiscovery and ExecutionBroker, sharing the same data model between the three services.


# -----------------------------------------------------

Work with Jesus to update the 0.2 interfaces.

The interfaces in the 0.2 confluence page are very simplified forms of the WorkflowExecution and ExecutionBroker interfaces. In particular the request editing API isn't covered in the 0.2 confluence yet.

SRCNet v0.2 Interfaces View
https://confluence.skatelescope.org/pages/viewpage.action?pageId=311707356

Sequence diagram
https://confluence.skatelescope.org/pages/viewpage.action?pageId=311713724

            Execute workflow
            Request offers
            Accept offer

          + Edit workflow
          + Get session status

        This work is already happening in the background and hopefully some of it will
        already be completed by the time we get to PI 28.

        Initial update to the 0.2 confluence page to include the API methods from
        WorkflowExecution and ExecutionBroker.

        Question - how do we represent the range of minimal to maximal messages ?

        This work  involve a series of meetings with Jesus, Chris and others to get
        agreement on how the API works.


# -----------------------------------------------------

Explore the metadata structures and vocabularies needed for Software Discovery.

Select a set of software applications used by our researchers and collect metadata about them.
* What the software does ..
* What versions, packaging, packager etc. are available.
* What the inputs and outputs are.
* What the hardware requirements are (cpu, memory, storage, gpu etc.)

Initial pass this would use Drupal as the platform for managing the content to get us off the ground quickly.

* Develop a database model that enables users to search for what they want.
* Extend the task description data model to describe the inputs/outputs in a way that enable the Science Gateway to and link them with data resources ?



# -----------------------------------------------------

A common pattern for global and local directories

Propose a pattern for global and local home and data directories that makes sense from the user's perspective.

This is a top-down approach to look at what we want to presnet to the user inside their applications (containers). The details of *how* this is implemented is already being looked at by other tasks.

If the user runs a notebook that takes a cube as input and outputs a slice of the cube in a separate file.
Where do we put the input and how do we tell the notebook where to find it ?
Where do we tell the notebook where to put the output ?

What happens if the user runs a second instance of the same notebook ?
Where do we put the input and how do we tell the notebook where to find it ?
Where do we tell the second notebook where to put the output, avoiding overwriting the output of the first one ?

What happens if the user runs a third instance of the same notebook on a different platform ?
Where do we put the input and how do we tell the notebook where to find it ?
Where do we tell the third notebook where to put the output ?
How do we bring the three outputs onto the same platform so they can be analysed together ?

The goal of this task isn't to develop an uber global filesystem.

The goal is to define a pattern that enables us to talk about things like the "user's home directory" with a common understanding of what we mean.
At the moment, some of us are takling about "user's home directory" when we mean the "user's home directory in Cavern on on a specific compute platform",
wheras I think many of our end users would expect "user's home directory" to be a global replicated thing that behaved like Drop Box.

Initial proposal would be a (virtual) directory structure that looked something like this :

    /global/users/home/<username>
    /global/users/data/<username>

    /global/groups/home/<groupname>
    /global/groups/data/<groupname>

    /local/users/home/<username>
    /local/users/data/<username>

    /local/groups/home/<groupname>
    /local/groups/data/<groupname>

    /global/platforms/<platformname>
        /local/users ...
        /local/groups ...


        How does this match with the idea of session based filenames ?
            per session directories created by ExecutionBroker
            with templating to replace names ?

        If the user launches the same notebook with different data,
        what do they expect to do and see ?

        If the user launches the same notebook on a different platform,
        what do they expect to do and see ?

        How does the SouthAfrican Idea system handle this ?
            Work with Julia to describe the use case

        How does this map to per project groups ?
            Does this solve how to share data products within a group
            Work with Julia to describe the use case

        This may help to solve shared data/workspace in Carta.
        https://confluence.skatelescope.org/pages/viewpage.action?pageId=335220284




# -----------------------------------------------------

Singularity in CANFAR

Request from Bonny Barkus <b.barkus@herts.ac.uk> in #proj-canfar in SKAO.Slack

Hi :slightly_smiling_face: I have been directed to ask my question here.
I hope that this is okay and that someone might be able to help me out.
I am wondering about running singularity on a CANFAR instance. As part
of the TEAL team we are currently looking at assessing the computational
resources used by different workflows. Therefore we would like to try this
on CANFAR as well as the HPC we have access to, to see how things might
differ, whether this is easy to do, and what the resource use is like.
Most of our workflows are in singularity containers. I have tried on a
couple of nodes (not recently for obvious reasons) to run a git clone,
singularity build and this obviously doesn't work and there is no access
to singularity. Now I have tried this in the terminal in my notebook session,
and I was going to try on the desktop, but it obviously is not working atm.
But I am assuming the answer is if it is installed on the instance I select
then I can use it.
How easy/difficult would it be to put singularity on CANFAR so that we can
run these resource monitoring tests? This will include being able to run it
on various nodes, for comparisons between nodes for example, and is it better
to be able to run it through a desktop instance or a notebook terminal instance
(on CANFAR)?
I have been pointed towards images.canfar.net, but I do not have access to it.
I am also not entirely IT savvy so some of the more complicated details might pass
me by (also meaning that I possibly will not know how to change one of them myself).
I will do my best, I have been catching up a lot in the past few weeks!
Thank you all for reading and any assistance :slightly_smiling_face:



    Architecture meeting in 2 weeks


Update the Execution Broker prototype to launch tasks in CANFAR

We did some work on this in an earlier iteration but it wasn't integrated into the Execution Broker code base.
Since then the Execution Broker code base has evolved to make it easier to integrate it with different execution platforms.

The problem that needs to be solved is how to handle asynchronous updates from the execution platform and update the Execution Broker databse.
The best solution would probably be use a RabbitMQ message bus to update the database in response to asynchronous messages from a separate task runner process that monitors the task in CANFAR.

Requires a Java programmer with expertise in both Spring and RabbitMQ.


Y: Developing unit tests for the registry client.
I: Creating unit tests that don't rely on external services.
T: Writing up ideas for backlog tasks


