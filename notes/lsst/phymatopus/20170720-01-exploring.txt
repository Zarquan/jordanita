#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2017, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#  
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

# -----------------------------------------------------
# Create a VM for Kafka, Sender, Listener.
#[user@trop03]

    createvm

        INFO : Node name [Umiawyth]
        INFO : Base name [fedora-25-docker-16G-20170713.qcow]
        INFO : Base path [/var/lib/libvirt/images/base/fedora-25-docker-16G-20170713.qcow]
        INFO : Disc name [Umiawyth.qcow]
        INFO : Disc size [16GiB]

    ssh Umiawyth # Kafka
    ssh Etalema  # Sender
    ssh Greand   # Listener

# -----------------------------------------------------
# Configure project settings.
#[user@virtual]

    if [ ! -e "${HOME}/projects.settings" ]
    then
        cat > "${HOME}/projects.settings" << EOF
PROJECTS_BASE="\${HOME}/projects"
EOF
    fi

# -----------------------------------------------------
# Configure Phymatopus settings.
#[user@virtual]

    if [ ! -e "${HOME}/phymatopus.settings" ]
    then
        cat > "${HOME}/phymatopus.settings" << EOF
source "\${HOME}/projects.settings"
PHYMATOPUS_BASE="\${PROJECTS_BASE:?}/phymatopus"
PHYMATOPUS_CODE="\${PHYMATOPUS_BASE:?}/code"
PHYMATOPUS_LSST="\${PHYMATOPUS_BASE:?}/lsst"
PHYMATOPUS_REPO='git@github.com:lsst-uk/phymatopus.git'
EOF
    fi

# -----------------------------------------------------
# Create our project base directory.
#[user@virtual]

    source "${HOME}/phymatopus.settings"
    mkdir -p "${PHYMATOPUS_BASE:?}"

# -----------------------------------------------------
# Checkout our source code.
#[user@virtual]

    source "${HOME}/phymatopus.settings"
    if [ ! -e "${PHYMATOPUS_CODE:?}" ]
    then
        mkdir -p $(dirname "${PHYMATOPUS_CODE:?}")
        pushd $(dirname "${PHYMATOPUS_CODE:?}")
            git clone "${PHYMATOPUS_REPO:?}" $(basename "${PHYMATOPUS_CODE:?}")
        popd
    else
        pushd "${PHYMATOPUS_CODE:?}"
            git pull
        popd
    fi

# -----------------------------------------------------
# Checkout Maria's code.
#[user@virtual]

    source "${HOME}/phymatopus.settings"

    mkdir -p "${PHYMATOPUS_LSST:?}/maria"
    pushd "${PHYMATOPUS_LSST:?}/maria"

        if [ ! -e 'alert_stream' ]
        then
            git clone git@github.com:mtpatter/alert_stream.git
        fi
        
    popd

# -----------------------------------------------------
# Checkout LSST-DM code.
#[user@virtual]

    source "${HOME}/phymatopus.settings"

    mkdir -p "${PHYMATOPUS_LSST:?}/lsst-dm"
    pushd "${PHYMATOPUS_LSST:?}/lsst-dm"

        if [ ! -e 'alert_stream' ]
        then
            git clone git@github.com:lsst-dm/sample-avro-alert.git
        fi
        
    popd

# -----------------------------------------------------
# -----------------------------------------------------
# Start the Kafka services.
#[user@Umiawyth]

    source "${HOME}/phymatopus.settings"

    docker-compose \
        --file "${PHYMATOPUS_LSST:?}/maria/alert_stream/docker-compose.yml" \
        up



# -----------------------------------------------------
# -----------------------------------------------------
# Build and run the event sender.
#[user@Etalema]

    source "${HOME}/phymatopus.settings"

    kafkahost=Umiawyth
    kafkahost=iota.virtual.metagrid.co.uk
    kafkaipv4=$(dig +short ${kafkahost:?})

    docker build \
        --tag 'alert_stream' \
        "${PHYMATOPUS_LSST:?}/maria/alert_stream"

    docker run \
        --rm \
        --tty \
        --interactive \
        --add-host "kafka:${kafkaipv4:?}" \
        alert_stream \
            python bin/sendAlertStream.py \
                test-stream \
                5


# -----------------------------------------------------
# -----------------------------------------------------
# Build and run the event listener.
#[user@Greand]

    source "${HOME}/phymatopus.settings"

    kafkahost=Umiawyth
    kafkahost=iota.virtual.metagrid.co.uk
    kafkaipv4=$(dig +short ${kafkahost:?})

    docker build \
        --tag 'alert_stream' \
        "${PHYMATOPUS_LSST:?}/maria/alert_stream"

    docker run \
        --rm \
        --tty \
        --interactive \
        --add-host "kafka:${kafkaipv4:?}" \
        alert_stream \
            python bin/monitorStream.py \
                --group monitor-group \
                test-stream



# -----------------------------------------------------
# -----------------------------------------------------
# Kafka virtual machine out of disc space.
#[root@Umiawyth]

    du -h / | grep '^[0-9]*G'

        ....
        12G	/var/lib/docker/volumes/8973fc2a361a843152d2a7172837d60acf13b01f9a88823d225b95bd6ba9e555/_data/test-stream-0
        12G	/var/lib/docker/volumes/8973fc2a361a843152d2a7172837d60acf13b01f9a88823d225b95bd6ba9e555/_data
        12G	/var/lib/docker/volumes/8973fc2a361a843152d2a7172837d60acf13b01f9a88823d225b95bd6ba9e555
        12G	/var/lib/docker/volumes
        17G	/var/lib/docker
        17G	/var/lib
        17G	/var
        18G	/

# -----------------------------------------------------
# Take down kafka containers.
#[user@Umiawyth]

    source phymatopus.settings 
    docker-compose \
        --file "${PHYMATOPUS_LSST:?}/maria/alert_stream/docker-compose.yml" \
        down

# -----------------------------------------------------
# Delete the orphaned volumes.
#[user@Umiawyth]

    docker volume ls

        DRIVER              VOLUME NAME
        local               756f8ffc343b8a527b28c9d77e005c263e7f8ed5f8e9752d1f60089c705ddc29
        local               7b3f00391dcfc13c6d69c4345d5dc23d924ef6293433a7178cde9df0f7fdd229
        local               8973fc2a361a843152d2a7172837d60acf13b01f9a88823d225b95bd6ba9e555
        local               cf5d2d1acd2638591c3962a4c7e1e855089e113d78e35e3146f36d020eef6503
        local               d6879f285a5ff63e79f04f4d546e8232fcd31798b40f3b57677010b934f13c69

    docker volume \
        rm $(docker volume ls -q)
        

# -----------------------------------------------------
# -----------------------------------------------------
# Add 1 Tera byte disc to the VM.
#[user@desktop]

    source "${HOME}/phymatopus.settings"
    gedit  "${PHYMATOPUS_CODE:?}/doc/notes/zrq/20170721-01-libvirt-data.txt" &


# -----------------------------------------------------
# -----------------------------------------------------
# Start the Kafka services.
#[user@Umiawyth]

    source "${HOME}/phymatopus.settings"

    docker-compose \
        --file "${PHYMATOPUS_LSST:?}/maria/alert_stream/docker-compose.yml" \
        up

# -----------------------------------------------------
# 15 hrs later, extended disc space is full.
#[user@Umiawyth]

    df -h /var/lib/docker/volumes

        Filesystem      Size  Used Avail Use% Mounted on
        /dev/vdb        1.0T 1023G  724K 100% /var/lib/docker/volumes

    du -h /var/lib/docker/volumes

        ....
        ....
        0	/var/lib/docker/volumes/b98326c09ab78d71118c22a96e2cd8647ad6b0e93e33893ba9e527f400dbdc18/_data/__consumer_offsets-41
        0	/var/lib/docker/volumes/b98326c09ab78d71118c22a96e2cd8647ad6b0e93e33893ba9e527f400dbdc18/_data/__consumer_offsets-32
        0	/var/lib/docker/volumes/b98326c09ab78d71118c22a96e2cd8647ad6b0e93e33893ba9e527f400dbdc18/_data/__consumer_offsets-3
        0	/var/lib/docker/volumes/b98326c09ab78d71118c22a96e2cd8647ad6b0e93e33893ba9e527f400dbdc18/_data/__consumer_offsets-13
        1020G	/var/lib/docker/volumes/b98326c09ab78d71118c22a96e2cd8647ad6b0e93e33893ba9e527f400dbdc18/_data/test-stream-0
        1020G	/var/lib/docker/volumes/b98326c09ab78d71118c22a96e2cd8647ad6b0e93e33893ba9e527f400dbdc18/_data
        1020G	/var/lib/docker/volumes/b98326c09ab78d71118c22a96e2cd8647ad6b0e93e33893ba9e527f400dbdc18
        1020G	/var/lib/docker/volumes


# -----------------------------------------------------
# Kafka service dies.
#[user@Umiawyth]

        kafka_1      | [2017-07-21 16:56:50,929] FATAL [Replica Manager on Broker 1]: Halting due to unrecoverable I/O error while handling produce request:  (kafka.server.ReplicaManager)
        kafka_1      | kafka.common.KafkaStorageException: I/O exception in append to log 'test-stream-0'
        kafka_1      | 	at kafka.log.Log.append(Log.scala:362)
        kafka_1      | 	at kafka.cluster.Partition$$anonfun$11.apply(Partition.scala:451)
        kafka_1      | 	at kafka.cluster.Partition$$anonfun$11.apply(Partition.scala:439)
        kafka_1      | 	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:213)
        kafka_1      | 	at kafka.utils.CoreUtils$.inReadLock(CoreUtils.scala:219)
        kafka_1      | 	at kafka.cluster.Partition.appendRecordsToLeader(Partition.scala:438)
        kafka_1      | 	at kafka.server.ReplicaManager$$anonfun$appendToLocalLog$2.apply(ReplicaManager.scala:389)
        kafka_1      | 	at kafka.server.ReplicaManager$$anonfun$appendToLocalLog$2.apply(ReplicaManager.scala:375)
        kafka_1      | 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
        kafka_1      | 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
        kafka_1      | 	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
        kafka_1      | 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
        kafka_1      | 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
        kafka_1      | 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
        kafka_1      | 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
        kafka_1      | 	at scala.collection.AbstractTraversable.map(Traversable.scala:104)
        kafka_1      | 	at kafka.server.ReplicaManager.appendToLocalLog(ReplicaManager.scala:375)
        kafka_1      | 	at kafka.server.ReplicaManager.appendRecords(ReplicaManager.scala:312)
        kafka_1      | 	at kafka.server.KafkaApis.handleProducerRequest(KafkaApis.scala:427)
        kafka_1      | 	at kafka.server.KafkaApis.handle(KafkaApis.scala:80)
        kafka_1      | 	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:62)
        kafka_1      | 	at java.lang.Thread.run(Thread.java:745)
        kafka_1      | Caused by: java.io.IOException: No space left on device
        kafka_1      | 	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
        kafka_1      | 	at sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:60)
        kafka_1      | 	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
        kafka_1      | 	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
        kafka_1      | 	at sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:211)
        kafka_1      | 	at org.apache.kafka.common.record.MemoryRecords.writeFullyTo(MemoryRecords.java:82)
        kafka_1      | 	at org.apache.kafka.common.record.FileRecords.append(FileRecords.java:159)
        kafka_1      | 	at kafka.log.LogSegment.append(LogSegment.scala:110)
        kafka_1      | 	at kafka.log.Log.append(Log.scala:425)
        kafka_1      | 	... 21 more

        zookeeper_1  | [2017-07-21 16:56:51,636] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn)
        zookeeper_1  | EndOfStreamException: Unable to read additional data from client sessionid 0x15d62f7c36f0002, likely client has closed socket
        zookeeper_1  | 	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
        zookeeper_1  | 	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
        zookeeper_1  | 	at java.lang.Thread.run(Thread.java:745)
        zookeeper_1  | [2017-07-21 16:56:54,667] INFO Closed socket connection for client /172.18.0.3:48018 which had sessionid 0x15d62f7c36f0002 (org.apache.zookeeper.server.NIOServerCnxn)

    alertstream_kafka_1 exited with code 1



    #
    # Config settings to limit size and age of logs.
    # https://docops.ca.com/ca-experience-collector/en/troubleshooting/digital-experience-collector-troubleshooting/apache-kafka-running-out-of-disk-space


    #
    #  Best Practices in Deploying/Using Kafka in Produciton 
    # https://community.hortonworks.com/articles/80813/kafka-best-practices-1.html


    #
    # Improve Docker compose file to locate log volumes on specific discs.
    # Production system needs more discs (many better than big).




        # The minimum age of a log file to be eligible for deletion due to age
    +   log.retention.hours=8

        # A size-based retention policy for logs. Segments are pruned from the log as long as the remaining
        # segments don't drop below log.retention.bytes. Functions independently of log.retention.hours.
    +   log.retention.bytes=1099510579200


       1M 1024*1024
       1G 1024*1024*1024
       1T 1024*1024*1024*1024
    1T-1M (1024*1024*1024*1024)-(1024*1024)=1099510579200

    #
    # Changing the properties while the system is running doesn't have any effect.
    # Need to restart !?



